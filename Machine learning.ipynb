{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport sklearn\nimport os\n\nfrom sklearn.metrics import mean_squared_error as mse\nfrom sklearn.neural_network import MLPClassifier\nfrom pickle import load","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open(\"/kaggle/input/faces.p\", \"rb\") as f: # выгружаем данные из txt файла faces.p\n    data_faces = load(f)\n    \nwith open(\"/kaggle/input/features.p\", \"rb\") as f: # выгружаем данные из txt файла features.p\n    data_features = load(f)\n\n# создаем общую дату, обьединяя content двух дат, делаем проверку на имя, если далее в проекте будут не нормализированные данные \ndata = [ \n{\"name\":face['name'],\n\"is_bearing\":face['is_bearing'],\n\"content\":{**face['content'],**feat['content']}} for face,feat in zip(data_faces,data_features) if face['name']==feat['name']]\n\ncontent = [content.get(\"content\") for content in data] # создаем массив массивов ключевых данных\nis_bearing = [is_bearing.get('is_bearing') for is_bearing in data] # массив определений подшипников (является соответственным с массивом content)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def parameters(content): # определяем все возможные параметры подшипников и загружаем их в массив\n    parameters_mass = []\n    \n    for dictionary in content:\n        \n        keys = dictionary.keys()\n        \n        for key in keys:         \n            if key in parameters_mass:\n                pass\n            else:\n                parameters_mass.append(key)\n                \n        \n    parameters_mass.sort()\n    \n    return parameters_mass\n        \nparameters_mass = parameters(content)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def y_filling(data):  \n    \n    y_train = []\n    y_test = []\n    \n    for i in data: # наполняем тренировачный массив игриков\n        if i:\n            y_train.append(1)\n        else:\n            y_train.append(0)\n            \n    y_test = y_train[:10] + y_train[-10:] # наполняем тестировачный массив игриков. так как количество данных не так много, \n                                          # тестовые игрики копируются из тренировачных, а не вырезаются\n    \n    return y_train,y_test\n\ndef x_filling(data,parameters_mass):\n    \n    train = []\n    x_train = []\n    x_test = []\n    \n    for dictionary in data: # наполняем тренировачный массив иксов, проходя по всем возможным параметрам из массива параметров\n        for param in parameters_mass:\n            train.append(dictionary.get(param,0)) \n\n        x_train.append(train)\n\n        train = []\n            \n    x_test = x_train[:10] + x_train[-10:] # наполняем тестировачный массив иксов. так как количество данных не так много, \n                                          # тестовые иксы копируются из тренировачных, а не вырезаются\n    return x_train,x_test\n        \n\n\n\nx_train,x_test = x_filling(content,parameters_mass) # создаем тренировачные и тестовые иксы\ny_train,y_test = y_filling(is_bearing) # создаем тренировачные и тестовые игрики\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mass_of_mass=[]\niterations = 50\n\nfor _ in range(iterations): \n    model = MLPClassifier(hidden_layer_sizes=(5,),max_iter=10000) # создание модели\n    model.fit(x_train, y_train)        # тренировка модели\n    mass_of_mass.append(model.predict(x_test))    # предсказание подшипника, загружаемое в массив\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = list(map(lambda x: sum(x)/iterations, zip(*mass_of_mass))) # итоговые предсказанные игрики\n\nprint(y_test)\nprint(y_pred)\nprint(mse(y_test,y_pred)) # средне квадратичная ошибка","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"answer=[]\n\nfor i in y_pred:\n    if i > 0.5:\n        answer.append('Подшипник есть')\n    else:\n        answer.append('Подшипника нет')\n        \nprint(answer)\n    ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}